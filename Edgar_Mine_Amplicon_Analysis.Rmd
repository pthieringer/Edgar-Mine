---
title: "Edgar Mine Amplicon Analysis"
output:
  html_document:
    df_print: paged
---

#Installation and Setup

Start off by installing and loading necessary packages for amplicon analysis.

```{r}
library(BiocManager)
library(ggplot2)
library(gridExtra)
library(dada2)
library(phyloseq)
library(DECIPHER)
library(phangorn)
library(stats)
library(knitr)
library(DESeq2)
library(devtools)
library(microbiomeSeq)
```


```{r}
set.seed(100)
```

Define the path variable so it points to the correct directory. Set the working directory first and then define the folder to work in.

```{r}
miseq_path <- "~/Edgar-Mine/Demultiplexed Files"
list.files(miseq_path)
```


# FILTER + TRIM

Filtering out low quality sequence reads by looking at quality scores. Also use FASTQC to check which files are good to use for the data and where to trim.

```{r}
#Sorting forward and reverse reads. 
fnFs <- sort(list.files(miseq_path, pattern="_R1_001.fastq"))
fnRs <- sort(list.files(miseq_path, pattern="_R2_001.fastq"))

sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)

fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
```

```{r}
#Sanity Check
fnFs[1:4]
fnRs[1:4]
```

```{r}
#Use the quality score profiles to double check and compare to FastQC/MultiQC
plotQualityProfile(fnFs[1:10])
plotQualityProfile(fnRs[1:10])
```

```{r}
#Defining the filepath for the trimmed reads
filt_path <- file.path(miseq_path, "filtered")

if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))
```

```{r}
#Here I am trimming the first 40 nucleotides because they likely produce unhelpful data. Since my primers were already removed and demultiplexed, I am including the matchIDs function to match my forward and reverse reads. 
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                    trimLeft = c(40,40), truncLen = c(220,220),
              maxN=0, maxEE=c(2,2), truncQ=4, rm.phix=TRUE, matchIDs = TRUE,
              compress=TRUE, multithread=TRUE)
head(out)
```



# DEREPLICATION

This step combines all the "unique" sequences into abundances for easier computation later on. The error learning step allows for detection of errors and matching error rates (if the points don't match up to the lines, then something likely went wrong).

```{r}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)

names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```

```{r}
plotErrors(errF)
plotErrors(errR)
```

```{r}
#This removes any final errors before merging
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
```

```{r}
dadaFs[[1]]
dadaRs[[1]]
```



# CONSTRUCTING SEQUENCE TABLE + REMOVE CHIMERAS

This step creates a DADA2 version of an ASV table.
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
table(nchar(getSequences(seqtabAll)))
```

```{r}
seqtabNoC <- removeBimeraDenovo(seqtabAll)
```

Additional steps to verify sanity check - should not lose too much of sample.
```{r}
sum(seqtabNoC)/sum(seqtabAll)
```

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtabNoC))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sampleNames
head(track)
```



# ASSIGNING TAXONOMY

Using formatted databases to assign taxonomy to samples and sequences
```{r}
#Depending on your work directory this may need to change
fastaRef <- "~/Edgar-Mine/silva_nr_v138_train_set.fa"
taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread = TRUE)
unname(head(taxTab))
```


##CONSTRUCT PHYLOGENETIC TREE

DADA2 makes a reference free analysis of phylogeny
```{r}
seqs <- getSequences(seqtabNoC)
names(seqs) <- seqs
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

Using the Phangorn package to help construct the tree
```{r}
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 1))
detach("package:phangorn", unload=TRUE)
```



# COMBINE DATA INTO PHYLOSEQ OBJECT

This step uses the Phyloseq package to combine all of the data associated with the samples into a single object that can be manipulated to observe amplicon data. The metadata file needs to be contained as a ".csv". 
```{r}
samdf <- read.csv("~/Edgar-Mine/Edgar_Metadata.csv",header=TRUE)
all(rownames(seqtabAll) %in% samdf$SampleID) #should come out TRUE
```

Create and keep the columns for all of the metadata variables. Need to list each of the variables in the keep.cols section.
```{r}
rownames(samdf) <- samdf$SampleID
keep.cols <- c("SampleID", "Borehole", "Collection_Date", "Days_Since_Previous_Extraction", "Total_Volume_Extracted_mL", "DO", "pH", "Temperature", "F", "Cl", "SO4")
samdf <- samdf[rownames(seqtabAll), keep.cols]
```

This creates the phyloseq object that can be used downstream for further analysis
```{r}
ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxTab),phy_tree(fitGTR$tree))
ps
```



# USING PHYLOSEQ

Can first create a table to view the number of observed counts for each phylum. This is a good chance to observe if there are small counts to filter out, but if working with low biomass, may be good to keep most things in.
```{r}
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```

Use this to filter out ambiguous phyla
```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```

Prevlance Filtering - the number of samples in which a taxon appears once
```{r}
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```

Compute the total average prevalence of the features in each phylum
```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

NOTE - only do this next step if needed to filter out specific phyla
```{r}
filterPhyla = c("list phyla of non concern")

ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```


Look at the prevlance filtering graphically to understand if there are outliers that need to be removed. 
```{r}
#Check if using the object "ps" or "ps1"

prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```


Good to set a prevlance threshold of 5% of total samples, then check how many samples are removed.
```{r}
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```

Execute the prevalance filter for further downstream analysis
```{r}
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```



# ANALYSIS OF PHYLOSEQ OBJECT AND METADATA

## SPECIES RICHNESS AND DIVERSITY - ALPHA DIVERSITY

Begin by looking at the Shannon and Simpson Diversity (measures of ...). Change "x" to the variable to plot by, and color by a distinct variable as well.
```{r}
plot_richness(ps2, x="Borehole", measures=c("Shannon", "Simpson"), color="Days_Since_Previous_Extraction")
```


## BETA DIVERSITY

Going to follow two ways of ordination by transforming the sample counts as a part of the workflow by Callahan et al. (2017) and rarefying the samples, as well as a Hellinger transformation for the rarefied samples. Each will be used in each ordination plot to observe any differences and/or unique distinctions.

Transformation/Rarefaction
```{r}
#Transformation from standard workflow - will not be hellinger tranformed
ps.prop <- transform_sample_counts(ps2, function(otu) otu/sum(otu))
```

```{r}
#Start by looking at the sample sums of the phyloseq object to detemine best lowest sample
sample_sums(ps2)
```

```{r}
ps_rare = rarefy_even_depth(ps2, sample.size = 10366, rngseed = 700)
sample_sums(ps_rare)
```


Principle Component Analysis (PCA)

Going to use the prcomp function from the stats package to create the PCA, and will not use the hellinger transformation. This is used to see how certain environmental variables are related in driving microbial community composition.
```{r}
#prcomp creates an object and then can be plotted with ggbiplot
ps.prop.pca <- prcomp(ps.prop, center = TRUE)
ps_rare_pca <- prcomp(ps_rare, center = TRUE)

#Make sure to look at the help section to define all of the necessary variables according to the metadata and whatnot

#For the Normal workflow with already transformed values
ggbiplot(ps.prop.pca, choices = 1:2, scale = 1, pc.biplot = TRUE, obs.scale = 1 - scale, var.scale = scale, groups = NULL, ellipse = FALSE, ellipse.prob = 0.68, labels = NULL, labels.size = 3, alpha = 1, var.axes = TRUE, circle = FALSE, circle.prob = 0.69, varname.size = 3, varname.adjust = 1.5, varname.abbrev = FALSE)
```

```{r}
#For the rarified object (don't need to Hellinger transform yet)
ggbiplot(ps_rare_pca, choices = 1:2, scale = 1, pc.biplot = TRUE, obs.scale = 1 - scale, var.scale = scale, groups = NULL, ellipse = FALSE, ellipse.prob = 0.68, labels = NULL, labels.size = 3, alpha = 1, var.axes = TRUE, circle = FALSE, circle.prob = 0.69, varname.size = 3, varname.adjust = 1.5, varname.abbrev = FALSE)
```


Hellinger Transformation for other Ordinations - just for rarified object
```{r}
ps_rare_hell <- vegan_stand(ps_rare, method = "hellinger")
```



## NMDS Ordination

```{r}
#For regular microbiome workflow without rarifaction and hellinger transformation
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
plot_ordination(ps.prop, ord.nmds.bray, type = "samples", color= "Days_Since_Previous_Extraction", shape = "SampleID", title="Bray NMDS")
```

```{r}
#The rarified object with Hellinger Transformation
ord.nmds.bray <- ordinate(ps_rare_hell, method="NMDS", distance="bray")
plot_ordination(ps_rare_hell, ord.nmds.bray, type = "samples", color= "Collection_Date", shape = "SampleID", label = NULL, title="Bray NMDS")
```



## CCA Ordination

First going to do a log transformation as denoted in the microbiome workflow for conducting a CCA analysis. Will also use the rarified Hellinger transformed object as well.
```{r}
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

```{r}
#The "formula" function can define which features to look at otherwise the analysis will incorperate all variables - eg: formula = pslog ~ SampleID + pH

ps_cca <- ordinate(pslog, method = "CCA", distance = "wunifrac", formula = pslog ~ SampleID + Borehole)
ps_cca
```

```{r}
#Now for the rarified sample with Hellinger transformation

ps_rare_cca <- ordinate(ps_rare_hell, method = "CCA", distance = "wunifrac", formula = )
ps_rare_cca
```



## MINIMUM SPANNING TREE

This test can show how a variable plays into grouping of samples.
```{r}
#SAMPLE_TYPE should be replaced by a variable in the metadata and is the variable to be tested, grouping should contain a variable from the metadata
gt <- graph_perm_test(ps, "Collection_Date", grouping = "SampleID",
                      distance = "jaccard", type = "mst")
gt$pval
```

```{r}
plotNet1=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm1=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet1, plotPerm1)
```




FUZZY SET ORDINATION (FSO)

This ordination is used to test effects of purturbation of environmental variables on community structure. A correlation between the original variable and the fuzzy set is reported. The significance of a particular variable is assessed by comparing a specified threshold p-value and the probability of obtaining a correlation between the data and fuzzy set.

Going to compute with original phyloseq object (ps2) and the rarified samples, not hellinger transformed.

Notes about the FSO: grouping_column is a variable of interest from the metadata to color the samples by, method is one of three different methods (look at microbiomeSEQ website and see what is best, default is 2), indices is representative of the variable of interest from the associated column in the metadata.
```{r}
ps_fuzzy <- generateFSO(ps2, grouping_column = "****", method = 2, indices = 2, filename = NULL)
ps_fuzzy
```

```{r}
ps_rare_fuzzy <- generateFSO(ps_rare, grouping_column = "***", method = 2, indices = 2, filename = NULL)
ps_rare_fuzzy
```

```{r}
plot_cca(ps_rare, grouping_column = "Borehole", 
    env.variables = NULL, num.env.variables = NULL, exclude.variables = "Borehole", 
    draw_species = FALSE)
```



# BAR PLOTS

This is a way to visulaize the key players in the samples. Can visulaize the top 20 (or other number - would only go to top 40) of taxa to deep dive on specific microbes. Also need to play around with the x variable to understand correlations.

```{r}
top20 <- names(sort(taxa_sums(ps2), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps2, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
```

```{r}
top40 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:40]
ps.top40 <- transform_sample_counts(ps2, function(OTU) OTU/sum(OTU))
ps.top40 <- prune_taxa(top40, ps.top40)
```

Now it is possible to plot basic visualizations. Use the guided additional facets from the phyloseq tutorial to group, color, and divide based off of additional variables.

```{r}
#basic visualization. Change fill to either go deeper or broader into phylogeny. Change x to variable of interest

plot_bar(ps.top20, x="SampleID", fill="Genus")
```

Deeper analysis and formatting
```{r}
#go to the phyloseq tutorial website
```



# AMPVIS 2 VISUALIZATIONS
These include heatmaps, boxplots, and some ordinations.

First must include the rarified phyloseq object with an appropriate number for the best determined lowest sample size. 
Only do this step if not previously implemented in the above steps.
```{r}
sample_sums(ps)

PROJECT_ps_rare = rarefy_even_depth(ps, sample.size = 6062, rngseed = 700)
sample_sums(PROJECT_ps_rare)
```

This step allows you to extract the metadata and OTU table and transform it to fit into an Ampvis object.
```{r}
obj <- edgar_ps_rare
t_otu <- t(data.frame(otu_table(obj)))
myotutable <- data.frame(OTU = rownames(t_otu@.Data),
                       t_otu@.Data,
                       phyloseq::tax_table(obj)@.Data,
                       check.names = FALSE
                       )
mymetadata <- data.frame(phyloseq::sample_data(obj), 
                       check.names = FALSE
                       )
edgar_ampvis2_obj <- amp_load(otutable = myotutable, metadata = mymetadata)
```

Heatmap of most abundant taxa - look at Ampvis2 website to understand what to include, and understand data in order to include most relevant data.
```{r}
amp_heatmap(edgar_ampvis2_obj,
            group_by = "SampleID",
            facet_by = "Collection_Date",
            tax_aggregate = "Genus",
            tax_add = "Phylum",
            tax_empty = "remove",
            tax_show = 12,
            color_vector = c("white", "darkred"),
            plot_colorscale = "sqrt",
            plot_values = TRUE) +
              theme(axis.text.x = element_text(angle = 45, size = 15, vjust = 1),
                    axis.text.y = element_text(size = 15),
                    legend.position = "right") +
  ggtitle("Taxanomic Classification by Sample") +
      theme(plot.title = element_text(size=20,face="bold",hjust = 0.5))
```

Boxplot ordered by mean read abundance. Another way to visualize also by grouping correctly. Look at Ampvis2 documentation to add more variables.
```{r}
amp_boxplot(edgar_ampvis2_obj,
            group_by = "Collection_Date",
            tax_show = 5,
            tax_add = "Phylum")
```

Ordination
```{r}
amp_ordinate(edgar_ampvis2_obj,
             type = "pca",
             transform = "hellinger",
             sample_color_by = "Hole_Retreived",
             sample_colorframe = TRUE,
             sample_colorframe_label = "Hole_Retreived",
             sample_colorframe_label_size = 7,
             sample_point_size = 5) +
  ggtitle("CA of Sample Location and Incubation Period") +
      theme(plot.title = element_text(size=20,face="bold",hjust = 0.5))
```

Time Series - showing a relative abundance over a period of time
```{r}
amp_timeseries(AalborgWWTPs,
  time_variable = "Date",
  group_by = "Plant",
  split = TRUE,
  scales = "free_y",
  tax_show = 9,
  tax_aggregate = "Genus",
  tax_add = "Phylum")
```



# ANOVA AND ANOISM TEST

To keep the metadata use the "samdf" object previously made from creating the phyloseq object.
```{r}
meta_project_anova <- samdf
```

Do the previous step similar in Ampvis2 but without the transformation to create a new object with the OTU table.
#decide whether or not to use the rarified object(project_ps_rare) or just the prevalance filtered object (ps2)
```{r}
project_obj <- ps2
anova_otu <- data.frame(otu_table(project_obj))
otu_project_anova <- data.frame(OTU = rownames(anova_otu@.Data),
                       anova_otu@.Data,
                       phyloseq::tax_table(project_obj)@.Data,
                       check.names = FALSE
                       )
```

Make a Euclidean distance transformation on the otu count table using DESeq2
```{r}
deseq_counts <- DESeqDataSetFromMatrix(otu_project_anova, colData = meta_project_anova, design = meta_project_anova$VARIABLE)

deseq_counts_vst <- varianceStabilizingTransformation(deseq_counts)
vst_trans_count_tab <- assay(deseq_counts_vst)
euc_dist <- dist(t(vst_trans_count_tab))
```

Anova Test - a way to see how community structure is homogenous or variable. This will tell us the difference between group dispersions (want the number to be close to 1 in order to represent a more consistent difference that can be explained by an adonis test).
```{r}
#Can be helpful to create subsamples of groups and remove certain samples to test how one variable may be related to a certain subset of samples
anova(betadisper(euc_dist, meta_project_anova$VARIABLE))
```

Adonis Test - this test should produce a very low number in order to define a statistically significant difference in samples due to a variable.
```{r}
adonis(euc_dist~meta_project_anova$variable)
```


